{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "from category_encoders import OrdinalEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import transformers\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (\n",
    "    RobertaConfig, RobertaTokenizer, RobertaModel,\n",
    "    get_linear_schedule_with_warmup\n",
    ")\n",
    "\n",
    "import time\n",
    "\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformers.__version__ # 2.11.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.__version__ # 0.23.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.__version__ # 1.5.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation - run on kaggle kernels as required packages come with its environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CUDA must be available in environment\n",
    "> Because training was done with CUDA available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 23\n",
    "\n",
    "random.seed(SEED)\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"data/Train.csv\")\n",
    "df_test = pd.read_csv(\"data/Test.csv\")\n",
    "\n",
    "sample_submission = pd.read_csv(\"data/SampleSubmission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert texts to lowercase and remove duplicate texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.text = df_train.text.str.lower()\n",
    "df_train = df_train.drop(df_train[df_train[[\"text\", \"label\"]].duplicated()].index).reset_index(drop = True)\n",
    "\n",
    "df_test.text = df_test.text.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode target labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = OrdinalEncoder(cols = [\"label\"], return_df = False, mapping = [{\"col\": \"label\", \"mapping\": {\"Depression\": 0, \"Alcohol\": 1, \"Suicide\": 2, \"Drugs\": 3}}])\n",
    "df_train.label = le.fit_transform(df_train.label)[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain maximum word length of a sample in train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['text'].apply(lambda x:len(str(x).split())).max(), df_test['text'].apply(lambda x:len(str(x).split())).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Process_Data(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len, task = \"train\"):\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.task = task\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        text = self.data.text[index]\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens = True,\n",
    "            max_length = self.max_len,\n",
    "            pad_to_max_length = True,\n",
    "            return_token_type_ids = True\n",
    "        )\n",
    "        \n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "\n",
    "        out = {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "        }\n",
    "        \n",
    "        # Set train data targets which is not applicable to test data\n",
    "        if self.task == \"train\":\n",
    "            out.update(\n",
    "                {\n",
    "                    'targets': torch.tensor(self.data.label[index], dtype = torch.long)\n",
    "                }\n",
    "            )\n",
    "            \n",
    "        return out\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate_predict(model, train_data, valid_data, test_data, loss_fn, lr, epochs, batch_size, warm_up_prop, device, n_samples_train, n_samples_val):\n",
    "    \n",
    "    train_loader = DataLoader(train_data, batch_size = batch_size, shuffle = True, num_workers = 0)\n",
    "    valid_loader = DataLoader(valid_data, batch_size = batch_size, shuffle = False, num_workers = 0)\n",
    "    test_loader = DataLoader(test_data, batch_size = batch_size, shuffle = False, num_workers = 0)\n",
    "    \n",
    "    num_training_steps = epochs * len(train_loader)\n",
    "    num_warmup_steps = int(warm_up_prop * num_training_steps)\n",
    "    optimizer = transformers.AdamW(model.parameters(), lr = lr, weight_decay = 0.1)\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps, num_training_steps)\n",
    "    \n",
    "    validation_loss = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Train\n",
    "        model.train()\n",
    "        start_time = time.time()\n",
    "        \n",
    "        batch_losses_train = []\n",
    "        n_correct = 0\n",
    "        avg_loss = 0\n",
    "        \n",
    "        for batch_index, data in enumerate(train_loader, 0):\n",
    "            \n",
    "            input_ids = data[\"ids\"].to(device, dtype = torch.long)\n",
    "            attention_mask = data[\"mask\"].to(device, dtype = torch.long)\n",
    "            targets = data[\"targets\"].to(device, dtype = torch.long)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            \n",
    "            batch_losses_train.append(loss.item())\n",
    "            _, preds = torch.max(outputs, dim = 1)\n",
    "            n_correct += torch.sum(preds == targets)\n",
    "            \n",
    "            loss.backward()            \n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        epoch_loss = np.mean(batch_losses_train)\n",
    "            \n",
    "            \n",
    "        # Evaluate\n",
    "        model.eval()\n",
    "        \n",
    "        batch_losses_val = []\n",
    "        n_correct_val = 0\n",
    "        avg_val_loss = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_index, data in enumerate(valid_loader, 0):\n",
    "                input_ids = data['ids'].to(device, dtype = torch.long)\n",
    "                attention_mask = data['mask'].to(device, dtype = torch.long)\n",
    "                targets = data['targets'].to(device, dtype = torch.long)\n",
    "                \n",
    "                val_outputs = model(input_ids, attention_mask)\n",
    "                loss = loss_fn(val_outputs, targets)\n",
    "                \n",
    "                batch_losses_val.append(loss.item())\n",
    "                _, val_preds = torch.max(val_outputs, dim = 1)\n",
    "                n_correct_val += torch.sum(val_preds == targets)\n",
    "                \n",
    "        epoch_loss_val = np.mean(batch_losses_val)\n",
    "        \n",
    "        if epoch == epochs - 1:\n",
    "            # Store val_loss of last epoch to get final loss \n",
    "            validation_loss += epoch_loss_val\n",
    "            \n",
    "        \n",
    "                \n",
    "        dt = time.time() - start_time\n",
    "        lr = scheduler.get_last_lr()[0]\n",
    "        \n",
    "        print(f'Epoch {epoch + 1}/{epochs} \\t lr={lr:.1e} \\t t={dt:.0f}s \\t loss={epoch_loss:.4f}, acc={n_correct.double() / n_samples_train:.4f} \\t val_loss={epoch_loss_val:.4f}, val_acc={n_correct_val.double() / n_samples_val:.4f}')\n",
    "\n",
    "    # Predict on test set \n",
    "    batch_outputs_test = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_index, data in enumerate(test_loader, 0):\n",
    "            ids = data[\"ids\"].to(device, dtype = torch.long)\n",
    "            mask = data[\"mask\"].to(device, dtype = torch.long)\n",
    "\n",
    "            test_outputs = model(ids, mask)\n",
    "            test_outputs = F.softmax(test_outputs, dim = 1)\n",
    "            test_outputs = test_outputs.cpu().detach().numpy()\n",
    "            batch_outputs_test.append(test_outputs)\n",
    "    \n",
    "    return validation_loss, np.vstack(batch_outputs_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple (5) runs of 5 cv folds - to reduce variability - 25 total runs\n",
    "> Each run with a different seed used in sampling data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RoBERTaModel(torch.nn.Module):\n",
    "    def __init__(self, freeze = False, n_layers = 12, n_attn_heads = 12):\n",
    "        super(RoBERTaModel, self).__init__()\n",
    "        \n",
    "        self.config = RobertaConfig.from_pretrained(\"roberta-base\")\n",
    "        \n",
    "        # Config\n",
    "        self.config.num_hidden_layers = n_layers\n",
    "        self.config.num_attention_heads = n_attn_heads\n",
    "        self.config.output_hidden_states = False\n",
    "        self.config.output_attentions = False\n",
    "        \n",
    "        # Roberta Model\n",
    "        self.roberta = RobertaModel.from_pretrained(\"roberta-base\", config = self.config)\n",
    "        if freeze:\n",
    "            for p in self.roberta.parameters():\n",
    "                p.requires_grad = False\n",
    "        \n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(0.6)\n",
    "        torch.manual_seed(SEED)\n",
    "        \n",
    "        # Classifier\n",
    "        self.classifier = torch.nn.Linear(self.config.hidden_size, 4)\n",
    "    \n",
    "    def forward(self, ids, mask):\n",
    "        sequence_outputs, pooled_output = self.roberta(ids, mask)\n",
    "        \n",
    "        # Output with Multi-sample dropout x5 - stacked\n",
    "        output = torch.stack([self.dropout(pooled_output) for _ in range(5)], dim = 0)\n",
    "        # Average dropouts\n",
    "        output = torch.mean(output, dim = 0)\n",
    "        torch.manual_seed(SEED)\n",
    "        # Output logits\n",
    "        logits = self.classifier(output)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "seeds = [16, 32, 42, 64, 128]\n",
    "\n",
    "validation_losses_per_run = []\n",
    "test_predictions_per_run = []\n",
    "\n",
    "# 5 runs\n",
    "for seed in seeds:\n",
    "    run_count = seeds.index(seed) + 1\n",
    "    print(f'Run {run_count}')\n",
    "\n",
    "    # 5 cv folds\n",
    "    kfold = StratifiedKFold(n_splits = 5, shuffle = True, random_state = seed)\n",
    "    splits = list(kfold.split(df_train, df_train.label))\n",
    "\n",
    "    validation_losses_per_fold = []\n",
    "    test_predicitons_per_fold = []  \n",
    "\n",
    "    # Folds\n",
    "    for i, (train_idx, valid_idx) in enumerate(splits):\n",
    "        tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "        # Use default RoBERTa params\n",
    "        model = RoBERTaModel()\n",
    "        model.to(device)\n",
    "        loss_fn = torch.nn.CrossEntropyLoss().to(device)\n",
    "        max_len = 35\n",
    "\n",
    "        # Data split\n",
    "        train_set = df_train.iloc[train_idx].reset_index(drop = True)\n",
    "        valid_set = df_train.iloc[valid_idx].reset_index(drop = True)\n",
    "        test_set = df_test.copy()\n",
    "\n",
    "        # Process Data into format required by Transformer model\n",
    "        train_set = Process_Data(train_set, tokenizer, max_len, \"train\")\n",
    "        valid_set = Process_Data(valid_set, tokenizer, max_len, \"train\")\n",
    "        test_set = Process_Data(test_set, tokenizer, max_len, \"test\")\n",
    "\n",
    "        print(f'Fold {i + 1}')\n",
    "\n",
    "        # Train, evaluate, predict\n",
    "        validation_loss, test_prediciton = train_evaluate_predict(model, train_data = train_set, valid_data = valid_set, test_data = test_set, loss_fn = loss_fn, lr = 5e-5, epochs = 3, batch_size = 8, warm_up_prop = 0, device = device, n_samples_train = len(train_set), n_samples_val = len(valid_set))\n",
    "        # Obtain validation result per fold\n",
    "        validation_losses_per_fold.append(validation_loss)\n",
    "        # Obtain test predictions per fold\n",
    "        test_predicitons_per_fold.append(test_prediciton)\n",
    "\n",
    "    # Obtain validation result per run\n",
    "    validation_losses_per_run.append(np.mean(validation_losses_per_fold))\n",
    "    # Obtain test predictions per run\n",
    "    test_predictions_per_run.append(np.mean(test_predicitons_per_fold, axis = 0))\n",
    "    \n",
    "    # Print result per run\n",
    "    print(f'Run {run_count} >>> Avg val_loss={np.mean(validation_losses_per_fold)}, S/Dev={np.std(validation_losses_per_fold)}')\n",
    "\n",
    "print(\"=\" * 100)\n",
    "# Print summary validation result of all runs\n",
    "print(f'Total avg val_loss={np.mean(validation_losses_per_run)}, S/Dev={np.std(validation_losses_per_run)}')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total avg val_loss=0.38818032202124597, S/Dev=0.018028698830688163 - raw_data, 35max_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate test predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = np.mean(test_predictions_per_run, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.Depression = test_preds[:,0]\n",
    "sample_submission.Alcohol = test_preds[:,1]\n",
    "sample_submission.Suicide = test_preds[:,2]\n",
    "sample_submission.Drugs = test_preds[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.iloc[:,1:].idxmax(axis = 1).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv(\"submission.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
